GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/usr/local/anaconda3/envs/Lightning-Table/lib/python3.7/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:616: UserWarning: Checkpoint directory /Users/moeezmalik/Documents/Main/work/fraunhofer/thesis/Lightning-Table/checkpoint exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
  | Name            | Type                    | Params
------------------------------------------------------------
0 | pr_metric_75_50 | OneClassPrecisionRecall | 0
1 | pr_metric_75_75 | OneClassPrecisionRecall | 0
2 | pr_metric_75_90 | OneClassPrecisionRecall | 0
3 | model           | FasterRCNN              | 43.3 M
------------------------------------------------------------
43.0 M    Trainable params
225 K     Non-trainable params
43.3 M    Total params
173.025   Total estimated model params size (MB)
/usr/local/anaconda3/envs/Lightning-Table/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:241: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  category=PossibleUserWarning,
Dataset Information
Total Images in Dataset: 10
Number of Training Images: 8
Number of Evaluation Images: 2
Sanity Checking DataLoader 0:   0%|                                             | 0/1 [00:00<?, ?it/s]
/usr/local/anaconda3/envs/Lightning-Table/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:653: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...
  rank_zero_warn("Detected KeyboardInterrupt, attempting graceful shutdown...")